training_1: batch_size:8  learning_rate:0.001
training_2: batch_size:8  learning_rate:0.00001
training_3: batch_size:4  generator_learning_rate:1e-5 discriminator_learning_rate:0.0004  generator_loss_ration:500   ttur
training_4: batch_size:4  generator_learning_rate:1e-5 discriminator_learning_rate:0.0004  generator_loss_ration:500   ttur
training_5: batch_size:4  generator_learning_rate:1e-5 discriminator_learning_rate:0.0004  generator_loss_ration:20    ttur
training_6: batch_size:4  generator_learning_rate:1e-5 discriminator_learning_rate:0.0004  generator_loss_ration:0    ttur
training_7: batch_size:4  generator_learning_rate:1e-5 discriminator_learning_rate:0.0001  generator_loss_ration:0    ttur   corrected code error

training_8:batch_size:4  generator_learning_rate:0.0001 discriminator_learning_rate:0.0001 generator_loss_ration:0    train_ttur.py   delete refer img     有收敛倾向  意外停止

training_9:batch_size:8  generator_learning_rate:0.0001 discriminator_learning_rate:0.0001 generator_loss_ration:0    reference  只有pixel_loss 和 pose_net、disp_net
training_10:batch_size:8  generator_learning_rate:0.0001 discriminator_learning_rate:0.0001 generator_loss_ration:0    reference  只有pixel_loss 和 pose_net、disp_net   计算误差时src和tgt互换
  收敛倾向    5.12 收敛   继续训练  >  train_10.1.log
training_11:  继续训练training_8    5.12 收敛倾向  继续训练  > train_11.1.log
5.13 继续练 > train_11.2.log    5.13:修改数据  继续训练  >train_11.3.log
5.14 继续训练 >train_11.4.log     继续训练  > train_11.5.log(误差断崖式增长)
restore from model-803250 继续训练 > train_11.6.log
5.15 继续训练  > strain_11.7.log   -> train_11.8.log(loss断崖式）
-> train_11.9.log(loss问题) -> 11.10(loss问题) ->train_11.11.log
->train_11.12.log  

training_12:  train_ttur_new.py 8基础上加入refer_img  batch_size:16  learning_rate:0.0005 --> 修改learner
	5.13  继续训练   > train_12.1.log     5.13下午   trans_matrix矩阵计算方法错误 kill掉开始train_13

training_13: train_ttur_new.py 12基础上修改数据预处理代码    5.14  继续训练 > train_13.1.log     不收敛
问题按照论文里的说法T似乎表示的是从右到左的旋转矩阵   这里训练过程refer_img生成好像是从左到右
training_14: train_ttur_new.py   修改左右转换参数T 后重新训练观察是否收敛

training_15: model_new.py train_ttur_new.py discri_learning_rate = 0.001  discirminator_loss = 50 * discirminator_loss  误差小、学习率小  参数没调整
train_15.log 

training_16: 改造   不再是TTUR 不要使用GAN，使用pixel_loss和smooth_loss训练网络
不收敛   
training_17: 修改   重新训练  不收敛

training_18: 修改输出层激活函数  添加正则化  不收敛  

training_19: 修改训练变量   重新开始训练 train_19.log   不收敛、KILL

training_20: 重新继续训练11 train_ttur.py 修改模型设置

training_21: 超参数设置与train_ttur.py相同  重新开始训练

training_22: train_ttur.py 增大学习率  kill

training_23: train_ttur.py 改变训练数据   不收敛  killed

training_24: train_ttur_new.py GANLearner  不收敛

training_25: Unsupervised_train.py  pixel_loss + smooth_loss   不收敛

training_26: train_ttur_new.py   不收敛   改pixel_loss损失函数为reduce_mean

training_27: unSupervised_train.py   不收敛  改pixel_loss损失函数为reduce_mean

training_28: train_ttur_new.py   pixel_loss reduce_sum --> reduce_mean 

training_29: Unsupervised_train.py   pixel_loss reduce_sum --> reduce_mean 







	投影方式不同  投影产生的像素误差是否可微   
	是否存在梯度消失

   data augmentation
